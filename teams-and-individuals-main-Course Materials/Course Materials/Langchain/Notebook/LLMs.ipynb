{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df130f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74e0ea32",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3c9a1d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nQ: What did the fish say when it hit the wall?\\nA: Dam!'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6aa52d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_result = llm.generate(['Tell me a joke', 'Tell me a poem'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43c7a9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generations=[[Generation(text='\\n\\nQ. What did the fish say when it hit the wall?\\nA. Dam!', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\nRoses are red,\\nViolets are blue,\\nSugar is sweet,\\nAnd so are you.', generation_info={'finish_reason': 'stop', 'logprobs': None})]] llm_output={'token_usage': {'total_tokens': 54, 'prompt_tokens': 8, 'completion_tokens': 46}, 'model_name': 'text-davinci-003'} run=[RunInfo(run_id=UUID('e4b19c97-dbb3-4354-9217-e05ae1dd1382')), RunInfo(run_id=UUID('effabd95-35ee-4555-85ff-ac905eafdb33'))]\n"
     ]
    }
   ],
   "source": [
    "print(llm_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b60cb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fb72554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The Rime of the Ancient Mariner by Samuel Taylor Coleridge\n",
      "\n",
      "It is an ancient Mariner,\n",
      "And he stoppeth one of three.\n",
      "\"By thy long grey beard and glittering eye,\n",
      "Now wherefore stopp'st thou me?\n",
      "\n",
      "\"The Bridegroom's doors are opened wide,\n",
      "And I am next of kin;\n",
      "The guests are met, the feast is set:\n",
      "May'st hear the merry din.\"\n",
      "\n",
      "He holds him with his skinny hand,\n",
      "\"There was a ship,\" quoth he.\n",
      "\"Hold off! unhand me, grey-beard loon!\"\n",
      "Eftsoons his hand dropt he.\n",
      "\n",
      "He holds him with his glittering eye—\n",
      "The Wedding-Guest stood still,\n",
      "And listens like a three years' child:\n",
      "The Mariner hath his will.\n",
      "\n",
      "The Wedding-Guest sat on a stone:\n",
      "He cannot choose but hear;\n",
      "And thus spake on that ancient man,\n",
      "The bright-eyed Mariner.\n",
      "\n",
      "\"The ship was cheered, the harbour cleared,\n",
      "Merrily did we drop\n",
      "Below the kirk, below the hill,\n",
      "Below the lighthouse top.\n",
      "\n",
      "\"The Sun"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(streaming=True, callbacks = [StreamingStdOutCallbackHandler()], temperature=0)\n",
    "resp = llm(\"Tell me a long poem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f56dd794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 41\n",
      "\tPrompt Tokens: 16\n",
      "\tCompletion Tokens: 25\n",
      "Successful Requests: 2\n",
      "Total Cost (USD): $0.00082\n"
     ]
    }
   ],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-002\", n=2, best_of=2)\n",
    "with get_openai_callback() as cb:\n",
    "    result = llm.generate([\"Tell me a flower name of yellow color\",\"Tell me another flower name of red color\"])\n",
    "    \n",
    "    print(cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6947567c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "        \"model_name\": \"text-davinci-003\",\r\n",
      "        \"temperature\": 0.7,\r\n",
      "        \"max_tokens\": 256,\r\n",
      "        \"top_p\": 1.0,\r\n",
      "        \"frequency_penalty\": 0.0,\r\n",
      "        \"presence_penalty\": 0.0,\r\n",
      "        \"n\": 1,\r\n",
      "        \"best_of\": 1,\r\n",
      "        \"request_timeout\": null,\r\n",
      "        \"_type\": \"openai\"\r\n",
      "    }"
     ]
    }
   ],
   "source": [
    "cat llm.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a559e7f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe colors of the Indian flag are saffron, white and green.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms.loading import load_llm\n",
    "llm = load_llm(\"llm.json\")\n",
    "llm(\"Tell me the colors of indian flag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f83ea65",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model_name=\"text-davinci-002\", n=2, best_of=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6d066ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9 µs, sys: 18 µs, total: 27 µs\n",
      "Wall time: 166 µs\n",
      "Tokens Used: 42\n",
      "\tPrompt Tokens: 4\n",
      "\tCompletion Tokens: 38\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.00084\n",
      "\n",
      "\n",
      "Why did the chicken cross the road?\n",
      "\n",
      "To get to the other side.\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "from langchain.cache import \n",
    "from langchain.callbacks import get_openai_callback\n",
    "langchain.llm_cache = InMemoryCache()\n",
    "\n",
    "%time\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    result = llm(\"Tell me a joke\")\n",
    "    print(cb)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "afe18ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
      "Wall time: 6.91 µs\n",
      "Tokens Used: 0\n",
      "\tPrompt Tokens: 0\n",
      "\tCompletion Tokens: 0\n",
      "Successful Requests: 0\n",
      "Total Cost (USD): $0.0\n",
      "\n",
      "\n",
      "Why did the chicken cross the road?\n",
      "\n",
      "To get to the other side.\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    result = llm(\"Tell me a joke\")\n",
    "    print(cb)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82044de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
      "Wall time: 5.72 µs\n",
      "Tokens Used: 94\n",
      "\tPrompt Tokens: 4\n",
      "\tCompletion Tokens: 90\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.00188\n",
      "\n",
      "\n",
      "\"The Raven\" by Edgar Allan Poe.\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    result = llm(\"Tell me a poem\")\n",
    "    print(cb)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71fd86c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
