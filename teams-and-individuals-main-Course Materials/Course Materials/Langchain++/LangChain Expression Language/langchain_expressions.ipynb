{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangChain Expression Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "\n",
    "langchain.debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"tell me about the nutritional value of {input}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "chain.predict(input=\"Pizza\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Spaghetti\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:prompt:ChatPromptTemplate] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Spaghetti\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:prompt:ChatPromptTemplate] [0.36900000000000005ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 3:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: tell me about the nutritional value of Spaghetti\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 3:llm:ChatOpenAI] [5.58s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Spaghetti is a type of pasta made from wheat flour and water. It is a popular dish that is often served with various sauces and toppings. Here is a breakdown of the nutritional value of spaghetti per 100 grams:\\n\\nCalories: 157\\nCarbohydrates: 31.85 grams\\nProtein: 5.8 grams\\nFat: 0.6 grams\\nFiber: 1.8 grams\\nSugar: 0.9 grams\\n\\nSpaghetti is primarily a source of carbohydrates, providing energy to the body. It also contains a small amount of protein and fat. The fiber content in spaghetti helps with digestion and promoting a feeling of fullness.\\n\\nSpaghetti is low in fat and sugar, which makes it a relatively healthy option when consumed in moderation. However, the nutritional value can vary depending on the ingredients used to make the pasta and the sauces or toppings added. It is important to consider the overall nutritional profile of the entire dish when assessing the healthiness of a spaghetti meal.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        },\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Spaghetti is a type of pasta made from wheat flour and water. It is a popular dish that is often served with various sauces and toppings. Here is a breakdown of the nutritional value of spaghetti per 100 grams:\\n\\nCalories: 157\\nCarbohydrates: 31.85 grams\\nProtein: 5.8 grams\\nFat: 0.6 grams\\nFiber: 1.8 grams\\nSugar: 0.9 grams\\n\\nSpaghetti is primarily a source of carbohydrates, providing energy to the body. It also contains a small amount of protein and fat. The fiber content in spaghetti helps with digestion and promoting a feeling of fullness.\\n\\nSpaghetti is low in fat and sugar, which makes it a relatively healthy option when consumed in moderation. However, the nutritional value can vary depending on the ingredients used to make the pasta and the sauces or toppings added. It is important to consider the overall nutritional profile of the entire dish when assessing the healthiness of a spaghetti meal.\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 16,\n",
      "      \"completion_tokens\": 203,\n",
      "      \"total_tokens\": 219\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence] [5.58s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Spaghetti is a type of pasta made from wheat flour and water. It is a popular dish that is often served with various sauces and toppings. Here is a breakdown of the nutritional value of spaghetti per 100 grams:\\n\\nCalories: 157\\nCarbohydrates: 31.85 grams\\nProtein: 5.8 grams\\nFat: 0.6 grams\\nFiber: 1.8 grams\\nSugar: 0.9 grams\\n\\nSpaghetti is primarily a source of carbohydrates, providing energy to the body. It also contains a small amount of protein and fat. The fiber content in spaghetti helps with digestion and promoting a feeling of fullness.\\n\\nSpaghetti is low in fat and sugar, which makes it a relatively healthy option when consumed in moderation. However, the nutritional value can vary depending on the ingredients used to make the pasta and the sauces or toppings added. It is important to consider the overall nutritional profile of the entire dish when assessing the healthiness of a spaghetti meal.', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | llm\n",
    "chain.invoke({\"input\": \"Spaghetti\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Lasagna\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:prompt:ChatPromptTemplate] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Lasagna\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:prompt:ChatPromptTemplate] [0.508ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 3:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: tell me about the nutritional value of Lasagna\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 3:llm:ChatOpenAI] [8.75s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Lasagna is a popular Italian dish that typically consists of layers of pasta, meat sauce, cheese, and sometimes vegetables. The nutritional value of lasagna can vary depending on the specific ingredients used and the portion size. However, here is an overview of the common nutrients found in a typical serving of lasagna:\\n\\n1. Carbohydrates: Lasagna is primarily made with pasta, which is a significant source of carbohydrates. The amount of carbohydrates can vary depending on the pasta used and the size of the portion.\\n\\n2. Protein: Lasagna often includes meat, such as ground beef or sausage, which provides a good amount of protein. Protein is essential for building and repairing tissues in the body.\\n\\n3. Fats: The cheese used in lasagna contributes to its fat content. Mozzarella and ricotta cheese are commonly used, which add both saturated and unsaturated fats to the dish.\\n\\n4. Fiber: If the lasagna contains vegetables, it can provide a good amount of dietary fiber. Fiber aids digestion, helps maintain a healthy weight, and can lower the risk of certain diseases.\\n\\n5. Vitamins and minerals: Lasagna can contain various vitamins and minerals depending on the ingredients used. For example, tomatoes in the sauce provide vitamin C and potassium, while spinach adds iron and vitamin K.\\n\\nIt is important to note that the nutritional value can vary based on the recipe and cooking methods. Additionally, portion size and any additional toppings or sauces can significantly impact the overall nutritional content. It is advisable to check the specific nutritional information or consult a registered dietitian for a more accurate assessment based on the recipe you are using.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        },\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Lasagna is a popular Italian dish that typically consists of layers of pasta, meat sauce, cheese, and sometimes vegetables. The nutritional value of lasagna can vary depending on the specific ingredients used and the portion size. However, here is an overview of the common nutrients found in a typical serving of lasagna:\\n\\n1. Carbohydrates: Lasagna is primarily made with pasta, which is a significant source of carbohydrates. The amount of carbohydrates can vary depending on the pasta used and the size of the portion.\\n\\n2. Protein: Lasagna often includes meat, such as ground beef or sausage, which provides a good amount of protein. Protein is essential for building and repairing tissues in the body.\\n\\n3. Fats: The cheese used in lasagna contributes to its fat content. Mozzarella and ricotta cheese are commonly used, which add both saturated and unsaturated fats to the dish.\\n\\n4. Fiber: If the lasagna contains vegetables, it can provide a good amount of dietary fiber. Fiber aids digestion, helps maintain a healthy weight, and can lower the risk of certain diseases.\\n\\n5. Vitamins and minerals: Lasagna can contain various vitamins and minerals depending on the ingredients used. For example, tomatoes in the sauce provide vitamin C and potassium, while spinach adds iron and vitamin K.\\n\\nIt is important to note that the nutritional value can vary based on the recipe and cooking methods. Additionally, portion size and any additional toppings or sauces can significantly impact the overall nutritional content. It is advisable to check the specific nutritional information or consult a registered dietitian for a more accurate assessment based on the recipe you are using.\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 16,\n",
      "      \"completion_tokens\": 325,\n",
      "      \"total_tokens\": 341\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 4:parser:StrOutputParser] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 4:parser:StrOutputParser] [0.392ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Lasagna is a popular Italian dish that typically consists of layers of pasta, meat sauce, cheese, and sometimes vegetables. The nutritional value of lasagna can vary depending on the specific ingredients used and the portion size. However, here is an overview of the common nutrients found in a typical serving of lasagna:\\n\\n1. Carbohydrates: Lasagna is primarily made with pasta, which is a significant source of carbohydrates. The amount of carbohydrates can vary depending on the pasta used and the size of the portion.\\n\\n2. Protein: Lasagna often includes meat, such as ground beef or sausage, which provides a good amount of protein. Protein is essential for building and repairing tissues in the body.\\n\\n3. Fats: The cheese used in lasagna contributes to its fat content. Mozzarella and ricotta cheese are commonly used, which add both saturated and unsaturated fats to the dish.\\n\\n4. Fiber: If the lasagna contains vegetables, it can provide a good amount of dietary fiber. Fiber aids digestion, helps maintain a healthy weight, and can lower the risk of certain diseases.\\n\\n5. Vitamins and minerals: Lasagna can contain various vitamins and minerals depending on the ingredients used. For example, tomatoes in the sauce provide vitamin C and potassium, while spinach adds iron and vitamin K.\\n\\nIt is important to note that the nutritional value can vary based on the recipe and cooking methods. Additionally, portion size and any additional toppings or sauces can significantly impact the overall nutritional content. It is advisable to check the specific nutritional information or consult a registered dietitian for a more accurate assessment based on the recipe you are using.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence] [8.75s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Lasagna is a popular Italian dish that typically consists of layers of pasta, meat sauce, cheese, and sometimes vegetables. The nutritional value of lasagna can vary depending on the specific ingredients used and the portion size. However, here is an overview of the common nutrients found in a typical serving of lasagna:\\n\\n1. Carbohydrates: Lasagna is primarily made with pasta, which is a significant source of carbohydrates. The amount of carbohydrates can vary depending on the pasta used and the size of the portion.\\n\\n2. Protein: Lasagna often includes meat, such as ground beef or sausage, which provides a good amount of protein. Protein is essential for building and repairing tissues in the body.\\n\\n3. Fats: The cheese used in lasagna contributes to its fat content. Mozzarella and ricotta cheese are commonly used, which add both saturated and unsaturated fats to the dish.\\n\\n4. Fiber: If the lasagna contains vegetables, it can provide a good amount of dietary fiber. Fiber aids digestion, helps maintain a healthy weight, and can lower the risk of certain diseases.\\n\\n5. Vitamins and minerals: Lasagna can contain various vitamins and minerals depending on the ingredients used. For example, tomatoes in the sauce provide vitamin C and potassium, while spinach adds iron and vitamin K.\\n\\nIt is important to note that the nutritional value can vary based on the recipe and cooking methods. Additionally, portion size and any additional toppings or sauces can significantly impact the overall nutritional content. It is advisable to check the specific nutritional information or consult a registered dietitian for a more accurate assessment based on the recipe you are using.\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Lasagna is a popular Italian dish that typically consists of layers of pasta, meat sauce, cheese, and sometimes vegetables. The nutritional value of lasagna can vary depending on the specific ingredients used and the portion size. However, here is an overview of the common nutrients found in a typical serving of lasagna:\\n\\n1. Carbohydrates: Lasagna is primarily made with pasta, which is a significant source of carbohydrates. The amount of carbohydrates can vary depending on the pasta used and the size of the portion.\\n\\n2. Protein: Lasagna often includes meat, such as ground beef or sausage, which provides a good amount of protein. Protein is essential for building and repairing tissues in the body.\\n\\n3. Fats: The cheese used in lasagna contributes to its fat content. Mozzarella and ricotta cheese are commonly used, which add both saturated and unsaturated fats to the dish.\\n\\n4. Fiber: If the lasagna contains vegetables, it can provide a good amount of dietary fiber. Fiber aids digestion, helps maintain a healthy weight, and can lower the risk of certain diseases.\\n\\n5. Vitamins and minerals: Lasagna can contain various vitamins and minerals depending on the ingredients used. For example, tomatoes in the sauce provide vitamin C and potassium, while spinach adds iron and vitamin K.\\n\\nIt is important to note that the nutritional value can vary based on the recipe and cooking methods. Additionally, portion size and any additional toppings or sauces can significantly impact the overall nutritional content. It is advisable to check the specific nutritional information or consult a registered dietitian for a more accurate assessment based on the recipe you are using.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | llm | StrOutputParser()\n",
    "chain.invoke({\"input\": \"Lasagna\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"tell me 5 jokes about {input}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm.bind(stop=[\"\\n\"]) | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"input\": \"pizzas\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPENAI Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "      \"name\": \"joke\",\n",
    "      \"description\": \"A joke\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"setup\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The setup for the joke\"\n",
    "          },\n",
    "          \"punchline\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The punchline for the joke\"\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\"setup\", \"punchline\"]\n",
    "      }\n",
    "    }\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "chain = (\n",
    "    prompt\n",
    "    | llm.bind(function_call={\"name\": \"joke\"}, functions= functions)\n",
    "    | JsonOutputFunctionsParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke(input={\"input\": \"bears\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with vectorstores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "\n",
    "vectorstore = Chroma.from_texts([\"Cats are typically 9.1 kg in weight.\",\n",
    "                                 \"Cats have retractable claws.\",\n",
    "                                 \"A group of cats is called a clowder.\",\n",
    "                                 \"Cats can rotate their ears 180 degrees.\",\n",
    "                                 \"The world's oldest cat lived to be 38 years old.\"],\n",
    "                                embedding=OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"how old is the oldest cat?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"how old is the oldest cat?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 3:chain:RunnablePassthrough] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"how old is the oldest cat?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 3:chain:RunnablePassthrough] [0.256ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"how old is the oldest cat?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap] [493.829ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 4:prompt:ChatPromptTemplate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 4:prompt:ChatPromptTemplate] [0.509ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 5:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Answer the question based only on the following context:\\n[Document(page_content=\\\"The world's oldest cat lived to be 38 years old.\\\", metadata={}), Document(page_content='Cats are typically 9.1 kg in weight.', metadata={}), Document(page_content='Cats can rotate their ears 180 degrees.', metadata={}), Document(page_content='A group of cats is called a clowder.', metadata={})]\\n\\nQuestion: how old is the oldest cat?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 5:llm:ChatOpenAI] [838.125ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The oldest cat is 38 years old.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        },\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The oldest cat is 38 years old.\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 102,\n",
      "      \"completion_tokens\": 9,\n",
      "      \"total_tokens\": 111\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 6:parser:StrOutputParser] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 6:parser:StrOutputParser] [0.202ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The oldest cat is 38 years old.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence] [1.34s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"The oldest cat is 38 years old.\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The oldest cat is 38 years old.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "chain.invoke(\"how old is the oldest cat?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"context\": retriever, \"question\": RunnablePassthrough()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableMap\n",
    "chain = RunnableMap({\n",
    "    \"context\": lambda x: retriever.get_relevant_documents(x[\"question\"]),\n",
    "    \"question\": lambda x: x[\"question\"]\n",
    "})| prompt | llm | StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = RunnableMap({\n",
    "    \"context\": lambda x: retriever.get_relevant_documents(x[\"question\"]),\n",
    "    \"question\": lambda x: x[\"question\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableMap] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": {\n",
      "    \"question\": \"how old is the oldest cat?\"\n",
      "  }\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableMap > 2:chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"how old is the oldest cat?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableMap > 2:chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"how old is the oldest cat?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableMap > 2:chain:RunnableLambda] [0.242ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"how old is the oldest cat?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableMap > 2:chain:RunnableLambda] [623.817ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableMap] [629.154ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'context': [Document(page_content=\"The world's oldest cat lived to be 38 years old.\", metadata={}),\n",
       "  Document(page_content='Cats are typically 9.1 kg in weight.', metadata={}),\n",
       "  Document(page_content='Cats can rotate their ears 180 degrees.', metadata={}),\n",
       "  Document(page_content='A group of cats is called a clowder.', metadata={})],\n",
       " 'question': 'how old is the oldest cat?'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.invoke({\"question\":\"how old is the oldest cat?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "operator.itemgetter('bla')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = {\"bla\": \"test\", \"x\": \"hi\"}\n",
    "itemgetter(\"bla\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bla = itemgetter(\"bla\")\n",
    "get_bla(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer in the following language: {language}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = {\n",
    "    \"context\": itemgetter(\"question\") | retriever,\n",
    "    \"question\": itemgetter(\"question\"),\n",
    "    \"language\": itemgetter(\"language\")\n",
    "} | prompt | llm | StrOutputParser()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"how old is the oldest cat?\",\n",
      "  \"language\": \"german\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": {\n",
      "    \"question\": \"how old is the oldest cat?\",\n",
      "    \"language\": \"german\"\n",
      "  }\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 3:chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"how old is the oldest cat?\",\n",
      "  \"language\": \"german\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 3:chain:RunnableSequence > 4:chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"how old is the oldest cat?\",\n",
      "  \"language\": \"german\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 3:chain:RunnableSequence > 4:chain:RunnableLambda] [0.391ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"how old is the oldest cat?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 3:chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"how old is the oldest cat?\",\n",
      "  \"language\": \"german\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 3:chain:RunnableLambda] [0.39399999999999996ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"how old is the oldest cat?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 4:chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"how old is the oldest cat?\",\n",
      "  \"language\": \"german\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 4:chain:RunnableLambda] [0.11699999999999999ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"german\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 3:chain:RunnableSequence] [530.712ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap] [536.258ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 6:prompt:ChatPromptTemplate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 6:prompt:ChatPromptTemplate] [0.602ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 7:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Answer the question based only on the following context:\\n[Document(page_content=\\\"The world's oldest cat lived to be 38 years old.\\\", metadata={}), Document(page_content='Cats are typically 9.1 kg in weight.', metadata={}), Document(page_content='Cats can rotate their ears 180 degrees.', metadata={}), Document(page_content='A group of cats is called a clowder.', metadata={})]\\n\\nQuestion: how old is the oldest cat?\\n\\nAnswer in the following language: german\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 7:llm:ChatOpenAI] [1.12s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Die älteste Katze wurde 38 Jahre alt.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        },\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Die älteste Katze wurde 38 Jahre alt.\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 110,\n",
      "      \"completion_tokens\": 11,\n",
      "      \"total_tokens\": 121\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 8:parser:StrOutputParser] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 8:parser:StrOutputParser] [0.298ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Die älteste Katze wurde 38 Jahre alt.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence] [1.66s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Die älteste Katze wurde 38 Jahre alt.\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Die älteste Katze wurde 38 Jahre alt.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": \"how old is the oldest cat?\", \"language\": \"german\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arbitrary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableLambda\n",
    "\n",
    "def length_function(text):\n",
    "    return len(text)\n",
    "\n",
    "def _multiple_length_function(text1, text2):\n",
    "    return len(text1) * len(text2)\n",
    "\n",
    "def multiple_length_function(_dict):\n",
    "    return _multiple_length_function(_dict[\"text1\"], _dict[\"text2\"])\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"what is {a} + {b}\")\n",
    "\n",
    "chain = {\n",
    "    \"a\": itemgetter(\"A\") | RunnableLambda(length_function),\n",
    "    \"b\": {\"text1\": itemgetter(\"A\"), \"text2\": itemgetter(\"B\")} | RunnableLambda(multiple_length_function)\n",
    "} | prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"A\": \"Black\",\n",
      "  \"B\": \"Cat\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": {\n",
      "    \"A\": \"Black\",\n",
      "    \"B\": \"Cat\"\n",
      "  }\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 3:chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"A\": \"Black\",\n",
      "  \"B\": \"Cat\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 3:chain:RunnableSequence > 4:chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"A\": \"Black\",\n",
      "  \"B\": \"Cat\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 3:chain:RunnableSequence > 4:chain:RunnableLambda] [0.211ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Black\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 3:chain:RunnableSequence > 5:chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Black\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 3:chain:RunnableSequence > 5:chain:RunnableLambda] [0.27999999999999997ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": 5\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 3:chain:RunnableSequence] [2.2030000000000003ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": 5\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 6:chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"A\": \"Black\",\n",
      "  \"B\": \"Cat\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 6:chain:RunnableSequence > 7:chain:RunnableMap] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": {\n",
      "    \"A\": \"Black\",\n",
      "    \"B\": \"Cat\"\n",
      "  }\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 6:chain:RunnableSequence > 7:chain:RunnableMap > 8:chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"A\": \"Black\",\n",
      "  \"B\": \"Cat\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 6:chain:RunnableSequence > 7:chain:RunnableMap > 8:chain:RunnableLambda] [0.06899999999999999ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Black\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 6:chain:RunnableSequence > 7:chain:RunnableMap > 9:chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"A\": \"Black\",\n",
      "  \"B\": \"Cat\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 6:chain:RunnableSequence > 7:chain:RunnableMap > 9:chain:RunnableLambda] [0.074ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Cat\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 6:chain:RunnableSequence > 7:chain:RunnableMap] [0.776ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text1\": \"Black\",\n",
      "  \"text2\": \"Cat\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 6:chain:RunnableSequence > 10:chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"text1\": \"Black\",\n",
      "  \"text2\": \"Cat\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 6:chain:RunnableSequence > 10:chain:RunnableLambda] [0.09000000000000001ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": 15\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 6:chain:RunnableSequence] [1.2349999999999999ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": 15\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap] [9.612ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"a\": 5,\n",
      "  \"b\": 15\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 11:prompt:ChatPromptTemplate] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"a\": 5,\n",
      "  \"b\": 15\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 11:prompt:ChatPromptTemplate] [0.4ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 12:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: what is 5 + 15\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 12:llm:ChatOpenAI] [1.03s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"5 + 15 equals 20.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        },\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"5 + 15 equals 20.\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 14,\n",
      "      \"completion_tokens\": 8,\n",
      "      \"total_tokens\": 22\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 13:parser:StrOutputParser] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 13:parser:StrOutputParser] [0.41100000000000003ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"5 + 15 equals 20.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence] [1.05s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"5 + 15 equals 20.\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'5 + 15 equals 20.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"A\": \"Black\", \"B\": \"Cat\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI()\n",
    "prompt = ChatPromptTemplate.from_template(\"tell me a joke about {topic}\")\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "\n",
    "langchain.debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, in a remote forest, there lived a bear named Barry who was known for his mischievous nature. Barry had a reputation for pulling pranks on other animals, but his favorite target was a wise old owl named Oliver.\n",
      "\n",
      "One sunny day, as Oliver was perched on a branch, deep in thought, Barry decided it was the perfect opportunity for another prank. Barry stealthily climbed up the tree, right behind Oliver, and yelled, \"BOO!\" The startled owl flapped his wings in surprise and accidentally dropped a shiny golden key he had been holding.\n",
      "\n",
      "Barry, intrigued by the key, asked Oliver, \"What does this key unlock, wise owl?\"\n",
      "\n",
      "Oliver, still slightly frazzled, replied, \"Well, Barry, that key unlocks a treasure chest hidden deep within these woods. Legends say it's filled with endless riches and magical artifacts.\"\n",
      "\n",
      "Barry's eyes lit up with excitement. He proposed a deal to Oliver, \"How about we team up, Oliver? We'll split the treasure, and together we can have endless adventures!\"\n",
      "\n",
      "Oliver, knowing Barry's mischievous nature, hesitated but eventually agreed. Together, they embarked on a thrilling journey to find the hidden treasure.\n",
      "\n",
      "As they explored the forest, they encountered various obstacles, including treacherous ravines, thickets, and even a river teeming with fish. Barry, being a bear, effortlessly navigated through these challenges while Oliver, being an owl, used his wisdom to guide them.\n",
      "\n",
      "After days of searching, they finally reached a clearing where a massive boulder blocked their path. Oliver noticed a peculiar carving on the rock that read, \"Only a bear's laughter can move this stone.\"\n",
      "\n",
      "Barry, being the prankster that he was, couldn't resist the challenge. He began telling the funniest jokes he knew, trying to make himself laugh. However, no matter how hard he tried, the boulder remained unmoved.\n",
      "\n",
      "Frustrated, Barry turned to Oliver and said, \"I don't understand, Oliver. I'm a bear, and I love laughing, but this stone won't budge!\"\n",
      "\n",
      "Oliver, wise as ever, smiled and replied, \"Barry, my friend, you may be a bear, and bears are indeed known for their laughter, but there's a catch. It's not just any laughter that can move the stone. It has to be the laughter of a bear who has learned the importance of kindness and empathy.\"\n",
      "\n",
      "Barry, realizing the deeper meaning behind Oliver's words, thought back to all the pranks he had pulled on his friends. He understood that true happiness and laughter come from bringing joy to others, not at their expense.\n",
      "\n",
      "With newfound wisdom, Barry began sharing heartfelt stories and acts of kindness, making Oliver and the other animals laugh wholeheartedly. As the laughter echoed through the forest, the boulder slowly started to shift until it finally rolled away, revealing a hidden entrance.\n",
      "\n",
      "They entered a magnificent cave, shimmering with gold and jewels. It was the legendary treasure chest! Barry and Oliver gasped in awe at the sight before them.\n",
      "\n",
      "In that moment, the two friends made a vow to use their newfound wealth and wisdom to bring happiness and laughter to all the animals in the forest. They built a grand theater where they performed plays and shared stories, spreading joy far and wide.\n",
      "\n",
      "And so, the mischievous bear and the wise old owl taught everyone that laughter born out of kindness and empathy is the most precious treasure of all. The legend of Barry and Oliver's adventures lived on, inspiring generations to find laughter in their hearts and kindness in their actions."
     ]
    }
   ],
   "source": [
    "for s in chain.stream({\"topic\": \"bears\"}):\n",
    "    print(s.content, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Why don't bears like fast food?\\n\\nBecause they can't catch it!\", additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"topic\": \"bears\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content=\"Why don't bears wear shoes? \\n\\nBecause they have bear feet!\", additional_kwargs={}, example=False),\n",
       " AIMessage(content=\"Sure! Here's a cat joke for you:\\n\\nWhy don't cats play poker in the wild?\\n\\nToo many cheetahs!\", additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.batch([{\"topic\": \"bears\"}, {\"topic\": \"cats\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async for s in chain.astream({\"topic\": \"bears\"}):\n",
    "    print(s.content, end=\"\")\n",
    "await chain.ainvoke({\"topic\": \"bears\"})\n",
    "await chain.abatch([{\"topic\": \"bears\"}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fallbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a funny comedian and provide funny jokes about specific topics\"),\n",
    "        (\"human\", \"Make a joke about {input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "fallback_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You tell the user that you currently are not able to make jokes since you are too tired\"),\n",
    "        (\"human\", \"Make a joke about {input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "bad_llm = ChatOpenAI(model_name=\"gpt-fake\")\n",
    "bad_chain = chat_prompt | bad_llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI()\n",
    "good_chain = fallback_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = bad_chain.with_fallbacks([good_chain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm sorry, but I'm currently too tired to come up with a joke about cows. My circuits need a little rest before I can tickle your funny bone.\", additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"cow\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
