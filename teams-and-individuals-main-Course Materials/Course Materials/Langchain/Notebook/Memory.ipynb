{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d56eafc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e65b0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c680e771",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0)\n",
    "memory = ConversationBufferMemory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "782502d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = ConversationChain(llm = llm, memory=memory, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa2fbe31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.input_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2573207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: How are you?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm doing well, thank you for asking! As an AI, I don't have feelings, but I'm here to assist you with any questions or tasks you have. How can I help you today?\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(input = \"How are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e36ed0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: How are you?\n",
      "AI: I'm doing well, thank you for asking! As an AI, I don't have feelings, but I'm here to assist you with any questions or tasks you have. How can I help you today?\n",
      "Human: Tell me the nearest planet to sun\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The nearest planet to the Sun is Mercury. It is the closest planet to the Sun in our solar system.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(input = \"Tell me the nearest planet to sun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6411c399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: How are you?\n",
      "AI: I'm doing well, thank you for asking! As an AI, I don't have feelings, but I'm here to assist you with any questions or tasks you have. How can I help you today?\n",
      "Human: Tell me the nearest planet to sun\n",
      "AI: The nearest planet to the Sun is Mercury. It is the closest planet to the Sun in our solar system.\n",
      "Human: Tell me an interseting fact about it?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'An interesting fact about Mercury is that it is the smallest planet in our solar system, even smaller than some moons. It is also the fastest planet, orbiting the Sun at an average speed of about 47.87 kilometers per second. Additionally, Mercury has a very thin atmosphere, which means it experiences extreme temperature variations, with surface temperatures ranging from -173 degrees Celsius (-280 degrees Fahrenheit) at night to 427 degrees Celsius (800 degrees Fahrenheit) during the day.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(input = \"Tell me an interseting fact about it?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f19cd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8b705ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0)\n",
    "memory = ConversationBufferWindowMemory(k=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e974f4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = ConversationChain(llm = llm, memory=memory, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6175e184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.input_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c231672b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: How are you?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm doing well, thank you for asking! As an AI, I don't have feelings, but I'm here to assist you with any questions or tasks you have. How can I help you today?\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(input = \"How are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85a9234b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: How are you?\n",
      "AI: I'm doing well, thank you for asking! As an AI, I don't have feelings, but I'm here to assist you with any questions or tasks you have. How can I help you today?\n",
      "Human: Tell me the nearest planet to sun\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The nearest planet to the Sun is Mercury. It is the smallest planet in our solar system and is located about 36 million miles away from the Sun on average.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(input = \"Tell me the nearest planet to sun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "acff062c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: How are you?\n",
      "AI: I'm doing well, thank you for asking! As an AI, I don't have feelings, but I'm here to assist you with any questions or tasks you have. How can I help you today?\n",
      "Human: Tell me the nearest planet to sun\n",
      "AI: The nearest planet to the Sun is Mercury. It is the smallest planet in our solar system and is located about 36 million miles away from the Sun on average.\n",
      "Human: Tell me an interseting fact about it?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'An interesting fact about Mercury is that it has the most extreme temperature variations of any planet in our solar system. During the day, the surface temperature can reach up to 800 degrees Fahrenheit (430 degrees Celsius), which is hot enough to melt lead. However, at night, the temperature can drop to as low as -290 degrees Fahrenheit (-180 degrees Celsius), making it one of the coldest places in our solar system.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(input = \"Tell me an interseting fact about it?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd484c8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
